{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbaf83ef-eb34-42f7-b1e5-7963762c1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import gradio as gr\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cee928e9-0eae-4a9a-8846-16d1b7df6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "334af68f-17e3-4a30-9b2f-cdb233427b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "747f855a-4f10-4e0e-8e31-cfcaeb1cbdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embeddings=np.load(\"embedding_matrix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59b2a1d9-44c7-4cc9-957e-2f4084b00509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fake_news(title, context):\n",
    "    # Preprocess the inputs\n",
    "    title = preprocess_text(title)\n",
    "    context = preprocess_text(context)\n",
    "    \n",
    "    # Tokenize the inputs\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts([title, context])\n",
    "    \n",
    "    title_seq = tokenizer.texts_to_sequences([title])\n",
    "    context_seq = tokenizer.texts_to_sequences([context])\n",
    "    \n",
    "    # Define maximum lengths for padding\n",
    "    max_len_title = 26\n",
    "    max_len_context = 10074\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_title_seq = pad_sequences(title_seq, maxlen=max_len_title, padding='post', truncating='post')\n",
    "    padded_context_seq = pad_sequences(context_seq, maxlen=max_len_context, padding='post', truncating='post')\n",
    "    \n",
    "    # Convert to NumPy arrays\n",
    "    inp1 = np.array(padded_title_seq)\n",
    "    inp2 = np.array(padded_context_seq)\n",
    "    \n",
    "    # Load the pre-trained model\n",
    "    model = tf.keras.models.load_model('model_arch_for_fake_news.h5')\n",
    "    model.load_weights(\"model_for_fakenews_13.keras\")\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict([inp1, inp2])\n",
    "    \n",
    "    # Interpret the prediction\n",
    "    if prediction[0][0] > 0.5:\n",
    "        return \"Fake News\"\n",
    "    else:\n",
    "        return \"Real News\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25be451c-d66b-411a-915e-6bfa98d80367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_fake_news,\n",
    "    inputs=[gr.Textbox(lines=2, placeholder=\"Enter the news title here...\"), \n",
    "            gr.Textbox(lines=15, placeholder=\"Enter the news context here...\")],\n",
    "    outputs=\"text\",\n",
    "    title=\"Fake News Detector\",\n",
    "    description=\"Enter the news title and context to check if it's fake or real.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1bfc77d-1862-4add-a361-71995f63ef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Launch the interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b089c-06da-4dea-baba-dcf2f6c8fb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ccdd5-bb9e-42b0-a7e7-bad556829567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
